# GMM Based Gait Library

## 聚类和最大似然估计

## 非线性拟合的基本方法

当我们收集到N组数据，$X_N, t_N=\lbrace x^{(n)}, t_n\rbrace ^N_{n=1}$，x为I维数据，输出t是实数值

我们期望从数据中推断出一个非线性函数$y(x;w)$来拟合输入输出数据，同时预测下一步的输出，期中w是y的参数

最简单的情况是使用固定的基函数，w为不同基函数的权重

例如，选择RBF(radial basis functions)作为基函数
$$
y(x;w)=\sum_{h=1}^{H}\omega_h\phi_h(x)
\\
\phi_h(x) = exp[-\frac{(x-c_h)^2}{2r^2}]
$$
虽然y对x是非线性的，但是对w是线性的，因此我们称该模型为线性模型。

我们还可以使用可以改变形状的基函数，同时权重也进行调整
$$
y(x;w)=\sum_{h=1}^{H}\omega_h^{(2)}tanh(\sum^{I}_{i=1}\omega^{(1)}_{hi}x+\omega^{(1)}_{h0})+\omega^{(2)}_0
$$
该形式等价于一个神经网络

在选择好合适的模型参数后，我们需要通过最大后验概率来估计模型参数
$$
P(w|t_N,X_N)=\frac{P(t_N|w,X_N)P(w)}{P(t_N|X_N)}
$$
该问题可以通过Laplace方法进行优化或者蒙特卡洛方法搜索最大值。

在获得参数的后验分布后，通过全概率公式边际化参数w来进行下一步的预测
$$
P(t_{N+1}|t_N,X_{N+1})=\int P(t_{N+1}|w,x^{(N+1)})P(w|t_N,X_N)d^Hw
$$
实际计算时也常用蒙特卡洛方法来近似计算，随机选取R个参数$w^{(r)}$
$$
P(t_{N+1}|t_N,X_{N+1})=\frac{1}{R}\sum_{r=1}^{R}P(t_{N+1}|w^{(r)},x^{N+1})
$$
如果不对y定义模型参数就产生了另一种非参数化的方法，通过直接最小化误差得到一个y的序列，其中比较常用的是spline smoothing method
$$
M(y(x)) = 1/2\beta\sum_{n=1}^{N}(y(x_n)-t_n)^2+1/2\alpha\int [y^{(p)}(x)]^2 dx
$$
通过指定p的阶数可以得到指定阶数的y，例如p=2则得到的y是三次样条曲线

## 从高斯分布到高斯过程

对有限维度问题来说，高斯分布可以被写作
$$
P(x|\mu,\delta)=\frac{1}{\sqrt{2\pi}\delta}exp(-\frac{(x-\mu)^2}{2\delta^2}) = \frac{1}{Z}exp[(x-\mu)^TA(x-\mu)]
$$
其中Z是$exp((x-\mu)^TA(x-\mu))$在x上的积分，归一化从而保证总积分为1

一个函数可以看作一个无限维度的向量，每一个点(y(x),x)对应一个维度

高斯过程是无穷维高斯分布的推广
$$
P(y(x)|\mu(x),A)=\frac{1}{Z}exp[-\frac{1}{2}(y(x)-\mu(x))^TA(y(x)-\mu(x))]
$$
